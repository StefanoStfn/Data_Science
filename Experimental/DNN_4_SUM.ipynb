{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yVgEvsNUbeba"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data creation\n",
        "class Generator:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.upper = 10\n",
        "        self.combo_list = []\n",
        "        self.__execute_computing()\n",
        "\n",
        "    def __execute_computing(self):\n",
        "        for a in range(0,self.upper):\n",
        "            for b in range(0,self.upper):\n",
        "                for c_in in range(0,2):\n",
        "                    c_out = 1 if a+b+c_in>=10 else 0\n",
        "                    y = a+b+c_in if a+b+c_in<10 else a+b+c_in-10\n",
        "                    self.combo_list.append([a, b, c_in, y, c_out])"
      ],
      "metadata": {
        "id": "GYeaOdLFiwxr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataCreator:\n",
        "    def __init__(self):\n",
        "        obj_gen = Generator()\n",
        "        self.array_gen = np.array(obj_gen.combo_list)\n",
        "        print(self.array_gen.shape)\n",
        "    def __call__(self):\n",
        "      return self.array_gen[:,:3], self.array_gen[:,3].reshape((-1,1)), self.array_gen[:,4].reshape((-1,1))\n",
        "\n",
        "\n",
        "X_train, S_train, C_train = DataCreator()()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiNT_kjkitEj",
        "outputId": "35ded3b8-b893-4635-f06e-bc6030ff0360"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X set shape: {X_train.shape}\")\n",
        "print(f\"Y set shape: {S_train.shape}\")\n",
        "print(f\"C set shape: {C_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5zDGMe7kL-d",
        "outputId": "0d299ec2-109b-4b23-ae7b-6c6cffe7d4e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X set shape: (200, 3)\n",
            "Y set shape: (200, 1)\n",
            "C set shape: (200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify that random sums are correct\n",
        "for _ in range(5):\n",
        "  index = random.randint(0,X_train.shape[0])\n",
        "  print(f\"These numbers summed: {X_train[index]} give S: {S_train[index]} and Cout: {C_train[index]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzOKHfRdkjPs",
        "outputId": "46a97313-2a81-4d22-bcdd-695f5b4939a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These numbers summed: [8 6 1] give S: [5] and Cout: [1]\n",
            "\n",
            "These numbers summed: [4 5 0] give S: [9] and Cout: [0]\n",
            "\n",
            "These numbers summed: [3 1 1] give S: [5] and Cout: [0]\n",
            "\n",
            "These numbers summed: [8 8 0] give S: [6] and Cout: [1]\n",
            "\n",
            "These numbers summed: [6 8 0] give S: [4] and Cout: [1]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model creation with functional API\n",
        "class BaseLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dense0 = tf.keras.layers.Dense(32, activation='relu',\n",
        "                                            input_shape=(None,3),\n",
        "                                            kernel_regularizer=tf.keras.regularizers.L2(0.01),\n",
        "                                            kernel_initializer='he_normal')\n",
        "        self.dense1 = tf.keras.layers.Dense(32, activation='relu',\n",
        "                                            kernel_regularizer=tf.keras.regularizers.L2(0.01),\n",
        "                                            kernel_initializer='he_normal')\n",
        "    def call(self, inputs):\n",
        "        x0 = inputs\n",
        "        x1 = self.dense0(x0)\n",
        "        return self.dense1(x1)\n",
        "\n",
        "class OutputLayers(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.cout = tf.keras.layers.Dense(1, activation='sigmoid',\n",
        "                                          kernel_initializer='he_normal')\n",
        "        self.sum0 = tf.keras.layers.Dense(32, activation='relu',\n",
        "                                          kernel_initializer='he_normal')\n",
        "        self.sum1 = tf.keras.layers.Dense(10, activation=None,\n",
        "                                          kernel_initializer='he_normal')\n",
        "    def call(self, inputs):\n",
        "        x0 = inputs\n",
        "        x1 = self.sum0(x0)\n",
        "        return self.cout(x0), self.sum1(x1)"
      ],
      "metadata": {
        "id": "R_mqY1k8lAhB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Branch_Net(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Branch_Net, self).__init__()\n",
        "        self.base = BaseLayer()\n",
        "        self.out = OutputLayers()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x0 = inputs\n",
        "        x1 = self.base(x0)\n",
        "        self.out2 = self.out(x1)\n",
        "        return self.out2"
      ],
      "metadata": {
        "id": "fXUVK5P2no4_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStop(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('output_1_accuracy') is not None and \\\n",
        "        logs.get('output_1_accuracy') == 1.0 and \\\n",
        "        logs.get('output_2_accuracy') is not None and \\\n",
        "        logs.get('output_2_accuracy') == 1.0:\n",
        "            print(\"\\nReached wanted accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True\n",
        "early_stop_cb = EarlyStop()"
      ],
      "metadata": {
        "id": "JIlMcQqXTDwe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Placing and Compiling Model\n",
        "model = Branch_Net()"
      ],
      "metadata": {
        "id": "REwA1tzQoC7m"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=[2000, 300, 300, 300]\n",
        "learning_rate = [2e-3, 8e-4, 2e-4, 5e-5]\n",
        "history = []\n",
        "for epoch, lr in zip(epochs, learning_rate):\n",
        "    model.compile(\n",
        "            loss={'output_1': 'binary_crossentropy',\n",
        "                  'output_2': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "            metrics={'output_1':'accuracy',\n",
        "                     'output_2': 'accuracy'})\n",
        "\n",
        "    history.append(model.fit(\n",
        "          X_train, (C_train, S_train),\n",
        "          epochs=epoch,\n",
        "          batch_size=4,\n",
        "          verbose=1,\n",
        "          callbacks=[early_stop_cb]))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsH36miIplVF",
        "outputId": "8b7b2c73-d45d-4b33-c717-5c740c5440b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "50/50 [==============================] - 1s 3ms/step - loss: 5.9325 - output_1_loss: 1.0001 - output_2_loss: 3.7878 - output_1_accuracy: 0.5700 - output_2_accuracy: 0.0700\n",
            "Epoch 2/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 4.1543 - output_1_loss: 0.5534 - output_2_loss: 2.6015 - output_1_accuracy: 0.6850 - output_2_accuracy: 0.0650\n",
            "Epoch 3/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 3.8810 - output_1_loss: 0.5121 - output_2_loss: 2.4645 - output_1_accuracy: 0.7550 - output_2_accuracy: 0.1050\n",
            "Epoch 4/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.8287 - output_1_loss: 0.4979 - output_2_loss: 2.4929 - output_1_accuracy: 0.7550 - output_2_accuracy: 0.0750\n",
            "Epoch 5/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.7230 - output_1_loss: 0.4887 - output_2_loss: 2.4467 - output_1_accuracy: 0.7700 - output_2_accuracy: 0.0950\n",
            "Epoch 6/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.5976 - output_1_loss: 0.4685 - output_2_loss: 2.3801 - output_1_accuracy: 0.7850 - output_2_accuracy: 0.0950\n",
            "Epoch 7/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.5961 - output_1_loss: 0.4617 - output_2_loss: 2.4179 - output_1_accuracy: 0.8050 - output_2_accuracy: 0.1250\n",
            "Epoch 8/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.4909 - output_1_loss: 0.4368 - output_2_loss: 2.3655 - output_1_accuracy: 0.8200 - output_2_accuracy: 0.0950\n",
            "Epoch 9/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 3.4852 - output_1_loss: 0.4418 - output_2_loss: 2.3788 - output_1_accuracy: 0.7900 - output_2_accuracy: 0.1150\n",
            "Epoch 10/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 3.3985 - output_1_loss: 0.4103 - output_2_loss: 2.3453 - output_1_accuracy: 0.8050 - output_2_accuracy: 0.1200\n",
            "Epoch 11/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.3747 - output_1_loss: 0.4178 - output_2_loss: 2.3342 - output_1_accuracy: 0.8650 - output_2_accuracy: 0.1150\n",
            "Epoch 12/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.3657 - output_1_loss: 0.3937 - output_2_loss: 2.3666 - output_1_accuracy: 0.8250 - output_2_accuracy: 0.1400\n",
            "Epoch 13/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.2795 - output_1_loss: 0.3861 - output_2_loss: 2.3047 - output_1_accuracy: 0.8400 - output_2_accuracy: 0.0850\n",
            "Epoch 14/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.2252 - output_1_loss: 0.3742 - output_2_loss: 2.2770 - output_1_accuracy: 0.8400 - output_2_accuracy: 0.1300\n",
            "Epoch 15/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.2540 - output_1_loss: 0.3887 - output_2_loss: 2.3052 - output_1_accuracy: 0.8150 - output_2_accuracy: 0.1250\n",
            "Epoch 16/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 3.2037 - output_1_loss: 0.3559 - output_2_loss: 2.3013 - output_1_accuracy: 0.8500 - output_2_accuracy: 0.1450\n",
            "Epoch 17/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.1404 - output_1_loss: 0.3521 - output_2_loss: 2.2551 - output_1_accuracy: 0.8650 - output_2_accuracy: 0.1350\n",
            "Epoch 18/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.1158 - output_1_loss: 0.3389 - output_2_loss: 2.2547 - output_1_accuracy: 0.8600 - output_2_accuracy: 0.1350\n",
            "Epoch 19/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.0805 - output_1_loss: 0.3193 - output_2_loss: 2.2501 - output_1_accuracy: 0.8850 - output_2_accuracy: 0.1350\n",
            "Epoch 20/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.0228 - output_1_loss: 0.3190 - output_2_loss: 2.2031 - output_1_accuracy: 0.8750 - output_2_accuracy: 0.1350\n",
            "Epoch 21/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 3.0371 - output_1_loss: 0.3168 - output_2_loss: 2.2302 - output_1_accuracy: 0.8650 - output_2_accuracy: 0.1200\n",
            "Epoch 22/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.9653 - output_1_loss: 0.2916 - output_2_loss: 2.1931 - output_1_accuracy: 0.8750 - output_2_accuracy: 0.1300\n",
            "Epoch 23/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.9701 - output_1_loss: 0.2823 - output_2_loss: 2.2155 - output_1_accuracy: 0.8750 - output_2_accuracy: 0.0900\n",
            "Epoch 24/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.8952 - output_1_loss: 0.2678 - output_2_loss: 2.1635 - output_1_accuracy: 0.8950 - output_2_accuracy: 0.1600\n",
            "Epoch 25/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.9008 - output_1_loss: 0.2576 - output_2_loss: 2.1870 - output_1_accuracy: 0.8800 - output_2_accuracy: 0.1350\n",
            "Epoch 26/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.8137 - output_1_loss: 0.2250 - output_2_loss: 2.1397 - output_1_accuracy: 0.9200 - output_2_accuracy: 0.1400\n",
            "Epoch 27/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 2.7860 - output_1_loss: 0.2184 - output_2_loss: 2.1243 - output_1_accuracy: 0.9100 - output_2_accuracy: 0.1850\n",
            "Epoch 28/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 2.6871 - output_1_loss: 0.1967 - output_2_loss: 2.0523 - output_1_accuracy: 0.9300 - output_2_accuracy: 0.2000\n",
            "Epoch 29/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 2.7000 - output_1_loss: 0.1944 - output_2_loss: 2.0726 - output_1_accuracy: 0.9500 - output_2_accuracy: 0.1850\n",
            "Epoch 30/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.6072 - output_1_loss: 0.1708 - output_2_loss: 2.0081 - output_1_accuracy: 0.9550 - output_2_accuracy: 0.2250\n",
            "Epoch 31/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.5275 - output_1_loss: 0.1646 - output_2_loss: 1.9376 - output_1_accuracy: 0.9400 - output_2_accuracy: 0.2750\n",
            "Epoch 32/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.5043 - output_1_loss: 0.1545 - output_2_loss: 1.9277 - output_1_accuracy: 0.9400 - output_2_accuracy: 0.2800\n",
            "Epoch 33/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.4450 - output_1_loss: 0.1449 - output_2_loss: 1.8803 - output_1_accuracy: 0.9700 - output_2_accuracy: 0.2350\n",
            "Epoch 34/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.3952 - output_1_loss: 0.1252 - output_2_loss: 1.8529 - output_1_accuracy: 0.9700 - output_2_accuracy: 0.3050\n",
            "Epoch 35/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 2.3407 - output_1_loss: 0.1182 - output_2_loss: 1.8068 - output_1_accuracy: 0.9800 - output_2_accuracy: 0.3350\n",
            "Epoch 36/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.3082 - output_1_loss: 0.1157 - output_2_loss: 1.7796 - output_1_accuracy: 0.9700 - output_2_accuracy: 0.2950\n",
            "Epoch 37/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.2504 - output_1_loss: 0.1162 - output_2_loss: 1.7229 - output_1_accuracy: 0.9650 - output_2_accuracy: 0.3100\n",
            "Epoch 38/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.1969 - output_1_loss: 0.1003 - output_2_loss: 1.6877 - output_1_accuracy: 0.9850 - output_2_accuracy: 0.3600\n",
            "Epoch 39/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.1967 - output_1_loss: 0.1035 - output_2_loss: 1.6867 - output_1_accuracy: 0.9750 - output_2_accuracy: 0.3500\n",
            "Epoch 40/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.1369 - output_1_loss: 0.1019 - output_2_loss: 1.6302 - output_1_accuracy: 0.9700 - output_2_accuracy: 0.3800\n",
            "Epoch 41/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.0871 - output_1_loss: 0.0845 - output_2_loss: 1.6002 - output_1_accuracy: 0.9950 - output_2_accuracy: 0.4200\n",
            "Epoch 42/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.0417 - output_1_loss: 0.0896 - output_2_loss: 1.5515 - output_1_accuracy: 0.9750 - output_2_accuracy: 0.3900\n",
            "Epoch 43/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 2.0152 - output_1_loss: 0.0812 - output_2_loss: 1.5347 - output_1_accuracy: 0.9800 - output_2_accuracy: 0.4350\n",
            "Epoch 44/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 2.0160 - output_1_loss: 0.0923 - output_2_loss: 1.5258 - output_1_accuracy: 0.9750 - output_2_accuracy: 0.4550\n",
            "Epoch 45/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.8962 - output_1_loss: 0.0837 - output_2_loss: 1.4161 - output_1_accuracy: 0.9850 - output_2_accuracy: 0.5300\n",
            "Epoch 46/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 1.9006 - output_1_loss: 0.0782 - output_2_loss: 1.4280 - output_1_accuracy: 0.9850 - output_2_accuracy: 0.5250\n",
            "Epoch 47/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.8295 - output_1_loss: 0.0777 - output_2_loss: 1.3594 - output_1_accuracy: 0.9750 - output_2_accuracy: 0.5450\n",
            "Epoch 48/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.8283 - output_1_loss: 0.0693 - output_2_loss: 1.3680 - output_1_accuracy: 0.9950 - output_2_accuracy: 0.5400\n",
            "Epoch 49/2000\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 1.8295 - output_1_loss: 0.0651 - output_2_loss: 1.3748 - output_1_accuracy: 0.9850 - output_2_accuracy: 0.5000\n",
            "Epoch 50/2000\n",
            "50/50 [==============================] - 1s 16ms/step - loss: 1.7519 - output_1_loss: 0.0642 - output_2_loss: 1.3000 - output_1_accuracy: 0.9900 - output_2_accuracy: 0.5400\n",
            "Epoch 51/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.7739 - output_1_loss: 0.0657 - output_2_loss: 1.3217 - output_1_accuracy: 0.9850 - output_2_accuracy: 0.5500\n",
            "Epoch 52/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.7182 - output_1_loss: 0.0568 - output_2_loss: 1.2774 - output_1_accuracy: 0.9950 - output_2_accuracy: 0.5100\n",
            "Epoch 53/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.6623 - output_1_loss: 0.0574 - output_2_loss: 1.2241 - output_1_accuracy: 0.9850 - output_2_accuracy: 0.5750\n",
            "Epoch 54/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.5859 - output_1_loss: 0.0482 - output_2_loss: 1.1588 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.6300\n",
            "Epoch 55/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.5646 - output_1_loss: 0.0522 - output_2_loss: 1.1352 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.6150\n",
            "Epoch 56/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.5537 - output_1_loss: 0.0531 - output_2_loss: 1.1239 - output_1_accuracy: 0.9950 - output_2_accuracy: 0.6200\n",
            "Epoch 57/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.5356 - output_1_loss: 0.0538 - output_2_loss: 1.1066 - output_1_accuracy: 0.9950 - output_2_accuracy: 0.6550\n",
            "Epoch 58/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.4715 - output_1_loss: 0.0404 - output_2_loss: 1.0581 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.6600\n",
            "Epoch 59/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.4781 - output_1_loss: 0.0366 - output_2_loss: 1.0690 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.6250\n",
            "Epoch 60/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.4285 - output_1_loss: 0.0395 - output_2_loss: 1.0192 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.6500\n",
            "Epoch 61/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.3718 - output_1_loss: 0.0385 - output_2_loss: 0.9651 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.6900\n",
            "Epoch 62/2000\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 1.3970 - output_1_loss: 0.0354 - output_2_loss: 0.9957 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.6700\n",
            "Epoch 63/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.3274 - output_1_loss: 0.0342 - output_2_loss: 0.9297 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7350\n",
            "Epoch 64/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.3315 - output_1_loss: 0.0350 - output_2_loss: 0.9348 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7050\n",
            "Epoch 65/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.3385 - output_1_loss: 0.0308 - output_2_loss: 0.9479 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7400\n",
            "Epoch 66/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.2526 - output_1_loss: 0.0310 - output_2_loss: 0.8639 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7450\n",
            "Epoch 67/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.2521 - output_1_loss: 0.0326 - output_2_loss: 0.8642 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7450\n",
            "Epoch 68/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.2454 - output_1_loss: 0.0277 - output_2_loss: 0.8643 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7700\n",
            "Epoch 69/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.2104 - output_1_loss: 0.0291 - output_2_loss: 0.8303 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7200\n",
            "Epoch 70/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.1943 - output_1_loss: 0.0293 - output_2_loss: 0.8168 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7750\n",
            "Epoch 71/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 1.1858 - output_1_loss: 0.0262 - output_2_loss: 0.8131 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7700\n",
            "Epoch 72/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 1.1890 - output_1_loss: 0.0339 - output_2_loss: 0.8110 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7150\n",
            "Epoch 73/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.1590 - output_1_loss: 0.0267 - output_2_loss: 0.7906 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7700\n",
            "Epoch 74/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.1183 - output_1_loss: 0.0263 - output_2_loss: 0.7525 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8050\n",
            "Epoch 75/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.1110 - output_1_loss: 0.0256 - output_2_loss: 0.7482 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7650\n",
            "Epoch 76/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 1.1422 - output_1_loss: 0.0323 - output_2_loss: 0.7748 - output_1_accuracy: 0.9950 - output_2_accuracy: 0.7500\n",
            "Epoch 77/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.0876 - output_1_loss: 0.0242 - output_2_loss: 0.7299 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7550\n",
            "Epoch 78/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 1.0288 - output_1_loss: 0.0214 - output_2_loss: 0.6764 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8350\n",
            "Epoch 79/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.0264 - output_1_loss: 0.0213 - output_2_loss: 0.6763 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8150\n",
            "Epoch 80/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.0268 - output_1_loss: 0.0203 - output_2_loss: 0.6803 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7900\n",
            "Epoch 81/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.0256 - output_1_loss: 0.0259 - output_2_loss: 0.6758 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8050\n",
            "Epoch 82/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9676 - output_1_loss: 0.0179 - output_2_loss: 0.6275 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8450\n",
            "Epoch 83/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9831 - output_1_loss: 0.0164 - output_2_loss: 0.6462 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8150\n",
            "Epoch 84/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9431 - output_1_loss: 0.0186 - output_2_loss: 0.6056 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8150\n",
            "Epoch 85/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9269 - output_1_loss: 0.0155 - output_2_loss: 0.5952 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.7950\n",
            "Epoch 86/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9656 - output_1_loss: 0.0271 - output_2_loss: 0.6250 - output_1_accuracy: 0.9950 - output_2_accuracy: 0.8100\n",
            "Epoch 87/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.9507 - output_1_loss: 0.0315 - output_2_loss: 0.6068 - output_1_accuracy: 0.9900 - output_2_accuracy: 0.8000\n",
            "Epoch 88/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8838 - output_1_loss: 0.0169 - output_2_loss: 0.5560 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8550\n",
            "Epoch 89/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8848 - output_1_loss: 0.0161 - output_2_loss: 0.5599 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8050\n",
            "Epoch 90/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8682 - output_1_loss: 0.0146 - output_2_loss: 0.5479 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8150\n",
            "Epoch 91/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.8520 - output_1_loss: 0.0125 - output_2_loss: 0.5360 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8750\n",
            "Epoch 92/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8458 - output_1_loss: 0.0139 - output_2_loss: 0.5305 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8100\n",
            "Epoch 93/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8243 - output_1_loss: 0.0139 - output_2_loss: 0.5113 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8250\n",
            "Epoch 94/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8004 - output_1_loss: 0.0119 - output_2_loss: 0.4916 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8350\n",
            "Epoch 95/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8141 - output_1_loss: 0.0125 - output_2_loss: 0.5070 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8550\n",
            "Epoch 96/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8099 - output_1_loss: 0.0166 - output_2_loss: 0.5009 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8400\n",
            "Epoch 97/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8009 - output_1_loss: 0.0158 - output_2_loss: 0.4951 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8800\n",
            "Epoch 98/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.7878 - output_1_loss: 0.0118 - output_2_loss: 0.4881 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8350\n",
            "Epoch 99/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.7664 - output_1_loss: 0.0112 - output_2_loss: 0.4694 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8800\n",
            "Epoch 100/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.7632 - output_1_loss: 0.0113 - output_2_loss: 0.4678 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8750\n",
            "Epoch 101/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.7286 - output_1_loss: 0.0104 - output_2_loss: 0.4361 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8800\n",
            "Epoch 102/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.7221 - output_1_loss: 0.0117 - output_2_loss: 0.4309 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8800\n",
            "Epoch 103/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.7744 - output_1_loss: 0.0107 - output_2_loss: 0.4872 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8250\n",
            "Epoch 104/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.7216 - output_1_loss: 0.0112 - output_2_loss: 0.4364 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8850\n",
            "Epoch 105/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.7177 - output_1_loss: 0.0101 - output_2_loss: 0.4353 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8900\n",
            "Epoch 106/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6725 - output_1_loss: 0.0097 - output_2_loss: 0.3929 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9000\n",
            "Epoch 107/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6729 - output_1_loss: 0.0087 - output_2_loss: 0.3965 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8950\n",
            "Epoch 108/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6869 - output_1_loss: 0.0101 - output_2_loss: 0.4116 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8750\n",
            "Epoch 109/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.7838 - output_1_loss: 0.0181 - output_2_loss: 0.5017 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8300\n",
            "Epoch 110/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6435 - output_1_loss: 0.0080 - output_2_loss: 0.3725 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9250\n",
            "Epoch 111/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6555 - output_1_loss: 0.0088 - output_2_loss: 0.3858 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9100\n",
            "Epoch 112/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6552 - output_1_loss: 0.0087 - output_2_loss: 0.3883 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8550\n",
            "Epoch 113/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6054 - output_1_loss: 0.0077 - output_2_loss: 0.3416 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 114/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5995 - output_1_loss: 0.0084 - output_2_loss: 0.3368 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9300\n",
            "Epoch 115/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6164 - output_1_loss: 0.0082 - output_2_loss: 0.3559 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8950\n",
            "Epoch 116/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5909 - output_1_loss: 0.0071 - output_2_loss: 0.3336 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9200\n",
            "Epoch 117/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5939 - output_1_loss: 0.0076 - output_2_loss: 0.3381 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9300\n",
            "Epoch 118/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5768 - output_1_loss: 0.0072 - output_2_loss: 0.3232 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9150\n",
            "Epoch 119/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5893 - output_1_loss: 0.0069 - output_2_loss: 0.3380 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9100\n",
            "Epoch 120/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5497 - output_1_loss: 0.0073 - output_2_loss: 0.3003 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9300\n",
            "Epoch 121/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5438 - output_1_loss: 0.0068 - output_2_loss: 0.2971 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9250\n",
            "Epoch 122/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5523 - output_1_loss: 0.0072 - output_2_loss: 0.3074 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 123/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5412 - output_1_loss: 0.0072 - output_2_loss: 0.2983 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9300\n",
            "Epoch 124/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5567 - output_1_loss: 0.0064 - output_2_loss: 0.3166 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9200\n",
            "Epoch 125/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5251 - output_1_loss: 0.0064 - output_2_loss: 0.2872 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9350\n",
            "Epoch 126/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5248 - output_1_loss: 0.0069 - output_2_loss: 0.2888 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9300\n",
            "Epoch 127/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5290 - output_1_loss: 0.0070 - output_2_loss: 0.2948 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9150\n",
            "Epoch 128/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5109 - output_1_loss: 0.0066 - output_2_loss: 0.2788 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9500\n",
            "Epoch 129/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5293 - output_1_loss: 0.0090 - output_2_loss: 0.2965 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9250\n",
            "Epoch 130/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5255 - output_1_loss: 0.0058 - output_2_loss: 0.2972 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9200\n",
            "Epoch 131/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5016 - output_1_loss: 0.0075 - output_2_loss: 0.2737 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9250\n",
            "Epoch 132/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5063 - output_1_loss: 0.0068 - output_2_loss: 0.2814 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9150\n",
            "Epoch 133/2000\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4969 - output_1_loss: 0.0054 - output_2_loss: 0.2749 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9200\n",
            "Epoch 134/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5075 - output_1_loss: 0.0061 - output_2_loss: 0.2861 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9300\n",
            "Epoch 135/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4916 - output_1_loss: 0.0058 - output_2_loss: 0.2720 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9350\n",
            "Epoch 136/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4692 - output_1_loss: 0.0062 - output_2_loss: 0.2513 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9350\n",
            "Epoch 137/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4963 - output_1_loss: 0.0062 - output_2_loss: 0.2808 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9000\n",
            "Epoch 138/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4579 - output_1_loss: 0.0056 - output_2_loss: 0.2445 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9450\n",
            "Epoch 139/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4479 - output_1_loss: 0.0058 - output_2_loss: 0.2368 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9500\n",
            "Epoch 140/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4545 - output_1_loss: 0.0065 - output_2_loss: 0.2444 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9450\n",
            "Epoch 141/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4924 - output_1_loss: 0.0069 - output_2_loss: 0.2837 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8900\n",
            "Epoch 142/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5755 - output_1_loss: 0.0092 - output_2_loss: 0.3651 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8450\n",
            "Epoch 143/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5000 - output_1_loss: 0.0054 - output_2_loss: 0.2937 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9250\n",
            "Epoch 144/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4666 - output_1_loss: 0.0075 - output_2_loss: 0.2589 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9450\n",
            "Epoch 145/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4572 - output_1_loss: 0.0051 - output_2_loss: 0.2536 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9150\n",
            "Epoch 146/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4218 - output_1_loss: 0.0053 - output_2_loss: 0.2194 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 147/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4103 - output_1_loss: 0.0045 - output_2_loss: 0.2106 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9350\n",
            "Epoch 148/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3910 - output_1_loss: 0.0044 - output_2_loss: 0.1934 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 149/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3871 - output_1_loss: 0.0046 - output_2_loss: 0.1912 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9500\n",
            "Epoch 150/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3842 - output_1_loss: 0.0042 - output_2_loss: 0.1904 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9600\n",
            "Epoch 151/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4016 - output_1_loss: 0.0045 - output_2_loss: 0.2088 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9600\n",
            "Epoch 152/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4715 - output_1_loss: 0.0070 - output_2_loss: 0.2769 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9100\n",
            "Epoch 153/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4402 - output_1_loss: 0.0052 - output_2_loss: 0.2474 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9250\n",
            "Epoch 154/2000\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3909 - output_1_loss: 0.0040 - output_2_loss: 0.2010 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 155/2000\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 0.3976 - output_1_loss: 0.0060 - output_2_loss: 0.2071 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 156/2000\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 0.3859 - output_1_loss: 0.0040 - output_2_loss: 0.1991 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9450\n",
            "Epoch 157/2000\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.3773 - output_1_loss: 0.0040 - output_2_loss: 0.1920 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 158/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4065 - output_1_loss: 0.0045 - output_2_loss: 0.2223 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9450\n",
            "Epoch 159/2000\n",
            "50/50 [==============================] - 1s 16ms/step - loss: 0.3733 - output_1_loss: 0.0049 - output_2_loss: 0.1900 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 160/2000\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.3463 - output_1_loss: 0.0039 - output_2_loss: 0.1654 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 161/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3574 - output_1_loss: 0.0042 - output_2_loss: 0.1780 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 162/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3533 - output_1_loss: 0.0038 - output_2_loss: 0.1750 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9600\n",
            "Epoch 163/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3751 - output_1_loss: 0.0050 - output_2_loss: 0.1965 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 164/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3401 - output_1_loss: 0.0042 - output_2_loss: 0.1632 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 165/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3489 - output_1_loss: 0.0035 - output_2_loss: 0.1737 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 166/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3724 - output_1_loss: 0.0044 - output_2_loss: 0.1968 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9350\n",
            "Epoch 167/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3355 - output_1_loss: 0.0034 - output_2_loss: 0.1620 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 168/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3627 - output_1_loss: 0.0043 - output_2_loss: 0.1895 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9500\n",
            "Epoch 169/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3515 - output_1_loss: 0.0052 - output_2_loss: 0.1780 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 170/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3337 - output_1_loss: 0.0043 - output_2_loss: 0.1625 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 171/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3342 - output_1_loss: 0.0043 - output_2_loss: 0.1643 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 172/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3143 - output_1_loss: 0.0042 - output_2_loss: 0.1460 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 173/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3416 - output_1_loss: 0.0037 - output_2_loss: 0.1753 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9500\n",
            "Epoch 174/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3609 - output_1_loss: 0.0041 - output_2_loss: 0.1949 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 175/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4124 - output_1_loss: 0.0090 - output_2_loss: 0.2419 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9150\n",
            "Epoch 176/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3658 - output_1_loss: 0.0045 - output_2_loss: 0.1989 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 177/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3414 - output_1_loss: 0.0052 - output_2_loss: 0.1738 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9550\n",
            "Epoch 178/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3113 - output_1_loss: 0.0034 - output_2_loss: 0.1473 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9550\n",
            "Epoch 179/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3935 - output_1_loss: 0.0062 - output_2_loss: 0.2285 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9000\n",
            "Epoch 180/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3142 - output_1_loss: 0.0034 - output_2_loss: 0.1525 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 181/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3013 - output_1_loss: 0.0055 - output_2_loss: 0.1395 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 182/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3312 - output_1_loss: 0.0036 - output_2_loss: 0.1721 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9450\n",
            "Epoch 183/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2879 - output_1_loss: 0.0036 - output_2_loss: 0.1302 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 184/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3706 - output_1_loss: 0.0032 - output_2_loss: 0.2146 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9500\n",
            "Epoch 185/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4987 - output_1_loss: 0.0093 - output_2_loss: 0.3364 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8700\n",
            "Epoch 186/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4336 - output_1_loss: 0.0055 - output_2_loss: 0.2743 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9250\n",
            "Epoch 187/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2912 - output_1_loss: 0.0027 - output_2_loss: 0.1353 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 188/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2786 - output_1_loss: 0.0030 - output_2_loss: 0.1238 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 189/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2927 - output_1_loss: 0.0028 - output_2_loss: 0.1396 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9600\n",
            "Epoch 190/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3274 - output_1_loss: 0.0034 - output_2_loss: 0.1745 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9450\n",
            "Epoch 191/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3319 - output_1_loss: 0.0032 - output_2_loss: 0.1798 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9600\n",
            "Epoch 192/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3014 - output_1_loss: 0.0030 - output_2_loss: 0.1498 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 193/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4011 - output_1_loss: 0.0040 - output_2_loss: 0.2487 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9050\n",
            "Epoch 194/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2874 - output_1_loss: 0.0046 - output_2_loss: 0.1346 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 195/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2702 - output_1_loss: 0.0030 - output_2_loss: 0.1198 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 196/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2649 - output_1_loss: 0.0029 - output_2_loss: 0.1160 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 197/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2690 - output_1_loss: 0.0032 - output_2_loss: 0.1211 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 198/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2769 - output_1_loss: 0.0031 - output_2_loss: 0.1301 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 199/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2672 - output_1_loss: 0.0030 - output_2_loss: 0.1214 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 200/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2664 - output_1_loss: 0.0032 - output_2_loss: 0.1215 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 201/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2634 - output_1_loss: 0.0029 - output_2_loss: 0.1197 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 202/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2490 - output_1_loss: 0.0031 - output_2_loss: 0.1063 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 203/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2487 - output_1_loss: 0.0030 - output_2_loss: 0.1069 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 204/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2549 - output_1_loss: 0.0031 - output_2_loss: 0.1140 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 205/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2378 - output_1_loss: 0.0029 - output_2_loss: 0.0981 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 206/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2742 - output_1_loss: 0.0036 - output_2_loss: 0.1347 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9600\n",
            "Epoch 207/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2708 - output_1_loss: 0.0026 - output_2_loss: 0.1327 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9550\n",
            "Epoch 208/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2610 - output_1_loss: 0.0032 - output_2_loss: 0.1228 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 209/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2456 - output_1_loss: 0.0031 - output_2_loss: 0.1082 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 210/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2645 - output_1_loss: 0.0028 - output_2_loss: 0.1286 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 211/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2376 - output_1_loss: 0.0029 - output_2_loss: 0.1029 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 212/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2424 - output_1_loss: 0.0042 - output_2_loss: 0.1078 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 213/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2245 - output_1_loss: 0.0026 - output_2_loss: 0.0922 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 214/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2553 - output_1_loss: 0.0033 - output_2_loss: 0.1232 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 215/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2568 - output_1_loss: 0.0027 - output_2_loss: 0.1246 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 216/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4779 - output_1_loss: 0.0086 - output_2_loss: 0.3391 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9000\n",
            "Epoch 217/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4397 - output_1_loss: 0.0043 - output_2_loss: 0.3025 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8750\n",
            "Epoch 218/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4024 - output_1_loss: 0.0052 - output_2_loss: 0.2637 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9100\n",
            "Epoch 219/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2612 - output_1_loss: 0.0030 - output_2_loss: 0.1241 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 220/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2377 - output_1_loss: 0.0019 - output_2_loss: 0.1026 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 221/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2502 - output_1_loss: 0.0022 - output_2_loss: 0.1159 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 222/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2379 - output_1_loss: 0.0024 - output_2_loss: 0.1044 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 223/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2512 - output_1_loss: 0.0023 - output_2_loss: 0.1187 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 224/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3665 - output_1_loss: 0.0034 - output_2_loss: 0.2337 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9200\n",
            "Epoch 225/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2397 - output_1_loss: 0.0027 - output_2_loss: 0.1083 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 226/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2025 - output_1_loss: 0.0020 - output_2_loss: 0.0728 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 227/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2041 - output_1_loss: 0.0021 - output_2_loss: 0.0755 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 228/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2301 - output_1_loss: 0.0022 - output_2_loss: 0.1024 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 229/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2234 - output_1_loss: 0.0027 - output_2_loss: 0.0959 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 230/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2187 - output_1_loss: 0.0021 - output_2_loss: 0.0927 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 231/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2277 - output_1_loss: 0.0024 - output_2_loss: 0.1022 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 232/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2426 - output_1_loss: 0.0024 - output_2_loss: 0.1176 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 233/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2116 - output_1_loss: 0.0022 - output_2_loss: 0.0872 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 234/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2069 - output_1_loss: 0.0020 - output_2_loss: 0.0835 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 235/2000\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.2393 - output_1_loss: 0.0030 - output_2_loss: 0.1157 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 236/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2036 - output_1_loss: 0.0022 - output_2_loss: 0.0810 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 237/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2303 - output_1_loss: 0.0015 - output_2_loss: 0.1094 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 238/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2152 - output_1_loss: 0.0022 - output_2_loss: 0.0938 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 239/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2063 - output_1_loss: 0.0023 - output_2_loss: 0.0854 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 240/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2087 - output_1_loss: 0.0025 - output_2_loss: 0.0883 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 241/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4124 - output_1_loss: 0.0096 - output_2_loss: 0.2856 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8750\n",
            "Epoch 242/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.4729 - output_1_loss: 0.0075 - output_2_loss: 0.3469 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8600\n",
            "Epoch 243/2000\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.3028 - output_1_loss: 0.0042 - output_2_loss: 0.1787 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9250\n",
            "Epoch 244/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2614 - output_1_loss: 0.0021 - output_2_loss: 0.1399 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 245/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2319 - output_1_loss: 0.0022 - output_2_loss: 0.1106 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 246/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2057 - output_1_loss: 0.0018 - output_2_loss: 0.0857 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 247/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2042 - output_1_loss: 0.0017 - output_2_loss: 0.0854 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 248/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1988 - output_1_loss: 0.0019 - output_2_loss: 0.0808 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 249/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2463 - output_1_loss: 0.0023 - output_2_loss: 0.1285 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9600\n",
            "Epoch 250/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2135 - output_1_loss: 0.0025 - output_2_loss: 0.0955 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 251/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1924 - output_1_loss: 0.0017 - output_2_loss: 0.0759 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 252/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1865 - output_1_loss: 0.0018 - output_2_loss: 0.0706 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 253/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1921 - output_1_loss: 0.0018 - output_2_loss: 0.0767 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 254/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1878 - output_1_loss: 0.0018 - output_2_loss: 0.0730 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 255/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1847 - output_1_loss: 0.0018 - output_2_loss: 0.0708 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 256/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2510 - output_1_loss: 0.0020 - output_2_loss: 0.1370 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9600\n",
            "Epoch 257/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2255 - output_1_loss: 0.0022 - output_2_loss: 0.1110 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 258/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1975 - output_1_loss: 0.0021 - output_2_loss: 0.0837 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 259/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1777 - output_1_loss: 0.0020 - output_2_loss: 0.0647 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 260/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1794 - output_1_loss: 0.0019 - output_2_loss: 0.0671 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 261/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1782 - output_1_loss: 0.0019 - output_2_loss: 0.0668 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 262/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3324 - output_1_loss: 0.0045 - output_2_loss: 0.2184 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8900\n",
            "Epoch 263/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1911 - output_1_loss: 0.0023 - output_2_loss: 0.0789 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 264/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2048 - output_1_loss: 0.0021 - output_2_loss: 0.0935 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 265/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1722 - output_1_loss: 0.0021 - output_2_loss: 0.0621 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 266/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1817 - output_1_loss: 0.0020 - output_2_loss: 0.0721 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 267/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1898 - output_1_loss: 0.0019 - output_2_loss: 0.0805 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 268/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1806 - output_1_loss: 0.0020 - output_2_loss: 0.0721 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 269/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1752 - output_1_loss: 0.0018 - output_2_loss: 0.0674 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 270/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1726 - output_1_loss: 0.0018 - output_2_loss: 0.0657 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 271/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1928 - output_1_loss: 0.0020 - output_2_loss: 0.0864 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 272/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1652 - output_1_loss: 0.0019 - output_2_loss: 0.0592 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 273/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1765 - output_1_loss: 0.0019 - output_2_loss: 0.0715 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 274/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2191 - output_1_loss: 0.0023 - output_2_loss: 0.1136 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 275/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3808 - output_1_loss: 0.0042 - output_2_loss: 0.2725 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9150\n",
            "Epoch 276/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2102 - output_1_loss: 0.0020 - output_2_loss: 0.1039 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 277/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1722 - output_1_loss: 0.0017 - output_2_loss: 0.0665 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 278/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1667 - output_1_loss: 0.0015 - output_2_loss: 0.0617 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 279/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1757 - output_1_loss: 0.0016 - output_2_loss: 0.0711 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 280/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1988 - output_1_loss: 0.0019 - output_2_loss: 0.0946 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 281/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1788 - output_1_loss: 0.0024 - output_2_loss: 0.0744 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 282/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1684 - output_1_loss: 0.0017 - output_2_loss: 0.0648 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 283/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1636 - output_1_loss: 0.0016 - output_2_loss: 0.0608 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 284/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1569 - output_1_loss: 0.0017 - output_2_loss: 0.0551 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 285/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1576 - output_1_loss: 0.0017 - output_2_loss: 0.0564 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 286/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1697 - output_1_loss: 0.0019 - output_2_loss: 0.0688 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 287/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1683 - output_1_loss: 0.0018 - output_2_loss: 0.0675 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 288/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2522 - output_1_loss: 0.0023 - output_2_loss: 0.1509 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9350\n",
            "Epoch 289/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8777 - output_1_loss: 0.0264 - output_2_loss: 0.7516 - output_1_accuracy: 0.9950 - output_2_accuracy: 0.8000\n",
            "Epoch 290/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2441 - output_1_loss: 0.0035 - output_2_loss: 0.1407 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9550\n",
            "Epoch 291/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2060 - output_1_loss: 0.0021 - output_2_loss: 0.1041 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9600\n",
            "Epoch 292/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1648 - output_1_loss: 0.0014 - output_2_loss: 0.0641 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 293/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1570 - output_1_loss: 0.0014 - output_2_loss: 0.0567 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 294/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1787 - output_1_loss: 0.0021 - output_2_loss: 0.0781 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 295/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1717 - output_1_loss: 0.0016 - output_2_loss: 0.0717 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 296/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1579 - output_1_loss: 0.0014 - output_2_loss: 0.0586 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 297/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1620 - output_1_loss: 0.0014 - output_2_loss: 0.0634 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 298/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1514 - output_1_loss: 0.0015 - output_2_loss: 0.0531 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 299/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1546 - output_1_loss: 0.0013 - output_2_loss: 0.0568 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 300/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1538 - output_1_loss: 0.0015 - output_2_loss: 0.0564 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 301/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1570 - output_1_loss: 0.0017 - output_2_loss: 0.0598 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 302/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1607 - output_1_loss: 0.0015 - output_2_loss: 0.0638 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 303/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1617 - output_1_loss: 0.0014 - output_2_loss: 0.0655 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 304/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2583 - output_1_loss: 0.0019 - output_2_loss: 0.1620 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9450\n",
            "Epoch 305/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2261 - output_1_loss: 0.0016 - output_2_loss: 0.1299 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 306/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1889 - output_1_loss: 0.0025 - output_2_loss: 0.0924 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 307/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1549 - output_1_loss: 0.0022 - output_2_loss: 0.0590 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 308/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1543 - output_1_loss: 0.0018 - output_2_loss: 0.0593 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 309/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1515 - output_1_loss: 0.0017 - output_2_loss: 0.0570 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 310/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1490 - output_1_loss: 0.0017 - output_2_loss: 0.0547 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 311/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1515 - output_1_loss: 0.0015 - output_2_loss: 0.0579 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 312/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1510 - output_1_loss: 0.0019 - output_2_loss: 0.0573 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 313/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1655 - output_1_loss: 0.0020 - output_2_loss: 0.0719 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 314/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1576 - output_1_loss: 0.0016 - output_2_loss: 0.0645 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 315/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1587 - output_1_loss: 0.0015 - output_2_loss: 0.0659 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 316/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1407 - output_1_loss: 0.0015 - output_2_loss: 0.0486 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 317/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1348 - output_1_loss: 0.0015 - output_2_loss: 0.0432 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 318/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1457 - output_1_loss: 0.0016 - output_2_loss: 0.0545 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 319/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1568 - output_1_loss: 0.0016 - output_2_loss: 0.0663 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 320/2000\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.1529 - output_1_loss: 0.0017 - output_2_loss: 0.0624 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 321/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1692 - output_1_loss: 0.0016 - output_2_loss: 0.0787 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 322/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1742 - output_1_loss: 0.0028 - output_2_loss: 0.0830 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 323/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1817 - output_1_loss: 0.0021 - output_2_loss: 0.0914 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 324/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5370 - output_1_loss: 0.0044 - output_2_loss: 0.4424 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9100\n",
            "Epoch 325/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.5431 - output_1_loss: 0.0028 - output_2_loss: 0.4496 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.8350\n",
            "Epoch 326/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2261 - output_1_loss: 0.0032 - output_2_loss: 0.1316 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9400\n",
            "Epoch 327/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1527 - output_1_loss: 0.0018 - output_2_loss: 0.0601 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 328/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1469 - output_1_loss: 0.0014 - output_2_loss: 0.0553 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 329/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1315 - output_1_loss: 0.0016 - output_2_loss: 0.0405 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 330/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1399 - output_1_loss: 0.0016 - output_2_loss: 0.0494 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 331/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1404 - output_1_loss: 0.0016 - output_2_loss: 0.0503 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 332/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1586 - output_1_loss: 0.0018 - output_2_loss: 0.0687 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 333/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1496 - output_1_loss: 0.0015 - output_2_loss: 0.0600 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 334/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1382 - output_1_loss: 0.0016 - output_2_loss: 0.0489 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 335/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1341 - output_1_loss: 0.0016 - output_2_loss: 0.0453 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 336/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1328 - output_1_loss: 0.0014 - output_2_loss: 0.0445 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 337/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1369 - output_1_loss: 0.0016 - output_2_loss: 0.0488 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 338/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1343 - output_1_loss: 0.0017 - output_2_loss: 0.0467 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 339/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1427 - output_1_loss: 0.0016 - output_2_loss: 0.0555 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 340/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1295 - output_1_loss: 0.0016 - output_2_loss: 0.0425 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 341/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1382 - output_1_loss: 0.0016 - output_2_loss: 0.0516 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 342/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1465 - output_1_loss: 0.0018 - output_2_loss: 0.0600 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 343/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.2694 - output_1_loss: 0.0034 - output_2_loss: 0.1812 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9200\n",
            "Epoch 344/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1772 - output_1_loss: 0.0021 - output_2_loss: 0.0897 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 345/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1753 - output_1_loss: 0.0017 - output_2_loss: 0.0876 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 346/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1409 - output_1_loss: 0.0015 - output_2_loss: 0.0539 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 347/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1716 - output_1_loss: 0.0013 - output_2_loss: 0.0851 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9650\n",
            "Epoch 348/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1626 - output_1_loss: 0.0025 - output_2_loss: 0.0745 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 349/2000\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.1375 - output_1_loss: 0.0014 - output_2_loss: 0.0510 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 350/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1374 - output_1_loss: 0.0014 - output_2_loss: 0.0516 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 351/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1261 - output_1_loss: 0.0014 - output_2_loss: 0.0413 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 352/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1612 - output_1_loss: 0.0014 - output_2_loss: 0.0768 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 353/2000\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1350 - output_1_loss: 0.0020 - output_2_loss: 0.0502 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 354/2000\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.1641 - output_1_loss: 0.0024 - output_2_loss: 0.0792 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9700\n",
            "Epoch 355/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1349 - output_1_loss: 0.0016 - output_2_loss: 0.0511 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 356/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1321 - output_1_loss: 0.0017 - output_2_loss: 0.0486 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 357/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1329 - output_1_loss: 0.0018 - output_2_loss: 0.0495 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 358/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1342 - output_1_loss: 0.0019 - output_2_loss: 0.0506 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9800\n",
            "Epoch 359/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1301 - output_1_loss: 0.0014 - output_2_loss: 0.0477 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 360/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1367 - output_1_loss: 0.0022 - output_2_loss: 0.0542 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 361/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1731 - output_1_loss: 0.0022 - output_2_loss: 0.0901 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 362/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1263 - output_1_loss: 0.0014 - output_2_loss: 0.0448 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 363/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1272 - output_1_loss: 0.0015 - output_2_loss: 0.0462 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 364/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1246 - output_1_loss: 0.0015 - output_2_loss: 0.0438 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 365/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1323 - output_1_loss: 0.0016 - output_2_loss: 0.0520 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 366/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5355 - output_1_loss: 0.0243 - output_2_loss: 0.4322 - output_1_accuracy: 0.9900 - output_2_accuracy: 0.8700\n",
            "Epoch 367/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.6375 - output_1_loss: 0.0427 - output_2_loss: 1.5154 - output_1_accuracy: 0.9900 - output_2_accuracy: 0.6050\n",
            "Epoch 368/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2466 - output_1_loss: 0.0023 - output_2_loss: 0.1625 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9550\n",
            "Epoch 369/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1716 - output_1_loss: 0.0015 - output_2_loss: 0.0882 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 370/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1389 - output_1_loss: 0.0014 - output_2_loss: 0.0558 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 371/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1406 - output_1_loss: 0.0013 - output_2_loss: 0.0581 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9850\n",
            "Epoch 372/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1322 - output_1_loss: 0.0012 - output_2_loss: 0.0501 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 373/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1314 - output_1_loss: 0.0012 - output_2_loss: 0.0496 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 374/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1283 - output_1_loss: 0.0012 - output_2_loss: 0.0468 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 375/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1261 - output_1_loss: 0.0011 - output_2_loss: 0.0450 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 376/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1286 - output_1_loss: 0.0012 - output_2_loss: 0.0478 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 377/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1231 - output_1_loss: 0.0011 - output_2_loss: 0.0427 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 378/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1215 - output_1_loss: 0.0011 - output_2_loss: 0.0414 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 379/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1480 - output_1_loss: 0.0012 - output_2_loss: 0.0679 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9750\n",
            "Epoch 380/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1187 - output_1_loss: 0.0012 - output_2_loss: 0.0388 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 381/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1305 - output_1_loss: 0.0012 - output_2_loss: 0.0509 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 382/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1184 - output_1_loss: 0.0011 - output_2_loss: 0.0392 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 383/2000\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1224 - output_1_loss: 0.0013 - output_2_loss: 0.0433 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 384/2000\n",
            "42/50 [========================>.....] - ETA: 0s - loss: 0.1209 - output_1_loss: 0.0014 - output_2_loss: 0.0420 - output_1_accuracy: 1.0000 - output_2_accuracy: 1.0000    \n",
            "Reached wanted accuracy so cancelling training!\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1265 - output_1_loss: 0.0014 - output_2_loss: 0.0476 - output_1_accuracy: 1.0000 - output_2_accuracy: 1.0000\n",
            "Epoch 1/300\n",
            "50/50 [==============================] - 1s 3ms/step - loss: 0.1154 - output_1_loss: 0.0013 - output_2_loss: 0.0375 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 2/300\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1111 - output_1_loss: 0.0014 - output_2_loss: 0.0339 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9900\n",
            "Epoch 3/300\n",
            "32/50 [==================>...........] - ETA: 0s - loss: 0.1071 - output_1_loss: 0.0012 - output_2_loss: 0.0308 - output_1_accuracy: 1.0000 - output_2_accuracy: 1.0000\n",
            "Reached wanted accuracy so cancelling training!\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1077 - output_1_loss: 0.0014 - output_2_loss: 0.0313 - output_1_accuracy: 1.0000 - output_2_accuracy: 1.0000\n",
            "Epoch 1/300\n",
            "50/50 [==============================] - 2s 5ms/step - loss: 0.1044 - output_1_loss: 0.0013 - output_2_loss: 0.0285 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 2/300\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1024 - output_1_loss: 0.0013 - output_2_loss: 0.0269 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 3/300\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1016 - output_1_loss: 0.0013 - output_2_loss: 0.0266 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 4/300\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1007 - output_1_loss: 0.0013 - output_2_loss: 0.0259 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 5/300\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1017 - output_1_loss: 0.0013 - output_2_loss: 0.0272 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 6/300\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.1006 - output_1_loss: 0.0013 - output_2_loss: 0.0263 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 7/300\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1000 - output_1_loss: 0.0014 - output_2_loss: 0.0260 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 8/300\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0993 - output_1_loss: 0.0013 - output_2_loss: 0.0255 - output_1_accuracy: 1.0000 - output_2_accuracy: 0.9950\n",
            "Epoch 9/300\n",
            "45/50 [==========================>...] - ETA: 0s - loss: 0.1000 - output_1_loss: 0.0013 - output_2_loss: 0.0266 - output_1_accuracy: 1.0000 - output_2_accuracy: 1.0000\n",
            "Reached wanted accuracy so cancelling training!\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0996 - output_1_loss: 0.0013 - output_2_loss: 0.0261 - output_1_accuracy: 1.0000 - output_2_accuracy: 1.0000\n",
            "Epoch 1/300\n",
            "36/50 [====================>.........] - ETA: 0s - loss: 0.0997 - output_1_loss: 0.0015 - output_2_loss: 0.0261 - output_1_accuracy: 1.0000 - output_2_accuracy: 1.0000\n",
            "Reached wanted accuracy so cancelling training!\n",
            "50/50 [==============================] - 1s 3ms/step - loss: 0.0981 - output_1_loss: 0.0013 - output_2_loss: 0.0247 - output_1_accuracy: 1.0000 - output_2_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out1_accuracy = history[0].history['output_1_accuracy']\n",
        "\n",
        "\n",
        "epochs = range(1,history[0].epoch[-1]+2)\n",
        "plt.plot(epochs, out1_accuracy, 'g', label='Cout accuracy')\n",
        "\n",
        "plt.title('Cout accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "VrT0r_Egpujq",
        "outputId": "2739b5f6-412f-4054-ce32-24063512368c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out2_accuracy = history[0].history['output_2_accuracy']\n",
        "plt.plot(epochs, out2_accuracy, 'b', label='Sum accuracy')\n",
        "plt.title('Sum accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "CZtGb_GVyZcl",
        "outputId": "451024fc-6cac-44fe-d16c-97ffc4513bb3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def number_equalizer(A: str, B: str):\n",
        "    if(len(A) > len(B)):\n",
        "        B = B.zfill(len(A))\n",
        "    else:\n",
        "        A = A.zfill(len(B))\n",
        "    return A, B"
      ],
      "metadata": {
        "id": "JIaEt4AIbDpS"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvSpUTgbwd0n",
        "outputId": "e85db000-e3d9-4421-c40c-9794c580033b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 55998789797999779099999999876559898987878776656375009082580295555 + \n",
            " 82580299999987877665637509987655709055555789797999779099989898985 = \n",
            "138579089797987656765637509864215608043434566454374788182570194540\n"
          ]
        }
      ],
      "source": [
        "SUM = \"\"\n",
        "starting=True\n",
        "Cout = 0\n",
        "\n",
        "A='55998789797999779099999999876559898987878776656375009082580295555'\n",
        "B='82580299999987877665637509987655709055555789797999779099989898985'\n",
        "\n",
        "A_n, B_n = number_equalizer(A, B)\n",
        "\n",
        "\n",
        "for (ai, bi) in zip(A_n[::-1], B_n[::-1]):\n",
        "    if(starting):\n",
        "        starting = False\n",
        "        evaluation = model.predict([[int(ai),int(bi),Cout]],verbose = 0)\n",
        "        SUM = str(np.argmax(evaluation[1][0])) + SUM\n",
        "    else:\n",
        "        evaluation = model.predict([[int(ai),int(bi),Cout]],verbose = 0)\n",
        "        sum = np.argmax(evaluation[1][0])\n",
        "        SUM = str(np.argmax(evaluation[1][0])) + SUM\n",
        "    Cout = 1 if evaluation[0][0][0] > 0.98 else 0\n",
        "if(Cout == 1):\n",
        "    SUM = f\"{Cout}\" + SUM\n",
        "if(Cout == 1) :\n",
        "    print(f\" {A} + \\n {B} = \\n{SUM}\")\n",
        "else:\n",
        "    print(f\"{A} + \\n{B} = \\n{SUM}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5f03S_v2gWQV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}